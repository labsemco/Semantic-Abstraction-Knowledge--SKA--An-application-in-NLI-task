{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import requests\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''\n",
    "        You are an expert in Recognizing Textual Entailment over pairs of Premise and Hypothesis.\n",
    "        Classify the relationship between the given Premise and Hypothesis as one of the following: \"Entailment\", \"Neutral\" or \"Contradiction\". \n",
    "\n",
    "        Premise: The investigation came about following the collapse of Barings Bank, when one of its traders based in Singapore, Nick Leeson, amassed losses of the order of 600-700 million without the bank being aware of it.\n",
    "        Hypothesis: No investigation came about following the collapse of Barings Bank, when one of its traders based in Singapore, Nick Leeson, amassed losses of the order of 600-700 million without the bank being aware of it.\n",
    "\n",
    "        Let's think step by step\n",
    "\n",
    "        Step 1: Identify all the relationships between terms from the premise to the hypothesis. This process is performed for each of the terms in the hypothesis.\n",
    "        Use the next format for relationships: (p_i,rel,h_j) where p_i is a term from the premise, h_j is a term from the hypothesis, and rel is the relation linking these terms. \n",
    "        If any terms of the hypothesis with an unknown relationship with terms in the premise, identify them as (,unknown,h_k) where h_k is in the hypothesis. \n",
    "        List the relationships found.\n",
    "\n",
    "        Step 2: Align all the relationships found with the NLI labels: Entailment, Neutral, Contradiction; classifying them into groups G1, G2, G3 and G4 according to the following:\n",
    "        G1: will contain the list of relationships that align with the entailment label\n",
    "        G2: will contain the list of relationships that align with the contradiction label \n",
    "        G3: will contain the list of relationships that align with the neutrality label\n",
    "        G4: will contain the list of terms of the hypothesis with an unknown relationship with the premise. \n",
    "\n",
    "        Step 3: Analyze each group of relationships and decide on the correct label for the premise and hypothesis presented.\n",
    "\n",
    "        Respond only using the template:\n",
    "        {\n",
    "        \"Answer\": \"\",\n",
    "        \"Explanation\": \"\",\n",
    "        \"G1\":[],\n",
    "        \"G2\":[],\n",
    "        \"G3\":[],\n",
    "        \"G4\":[]\n",
    "        }\n",
    "        Fill out the template.\n",
    "            '''\n",
    "    \n",
    "#print(prompt)\n",
    "# break\n",
    "data = {\n",
    "    \"prompt\": prompt,\n",
    "    \"model\": \"phi3\",\n",
    "    \"format\": \"json\",\n",
    "    \"stream\": False,\n",
    "    \"options\": {\"temperature\": 0,\n",
    "                \"num_ctx\":4096},\n",
    "}\n",
    "response = requests.post(\"http://localhost:11434/api/generate\", json=data, stream=False,timeout=180)\n",
    "#print(response.done)        \n",
    "json_data = json.loads(response.text)\n",
    "#print(json_data)\n",
    "print(\"Size:\",json_data[\"prompt_eval_count\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verification of complete information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AoT prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callLLM_AoT(model,dfg,ind):\n",
    "    prompt = '''\n",
    "                You are an expert in Recognizing Textual Entailment over pairs of Premise and Hypothesis.\n",
    "        Classify the relationship between the given Premise and Hypothesis as one of the following: \"Entailment\", \"Neutral\" or \"Contradiction\". \n",
    "\n",
    "        Premise: '''+dfg.at[ind,\"Texto\"]+'''\n",
    "        Hypothesis: '''+ dfg.at[ind,\"Hipotesis\"]+'''\n",
    "\n",
    "        Let's think step by step\n",
    "\n",
    "        Step 1: Identify all the relationships between terms from the premise to the hypothesis. This process is performed for each of the terms in the hypothesis.\n",
    "        Use the next format for relationships: (p_i,rel,h_j) where p_i is a term from the premise, h_j is a term from the hypothesis, and rel is the relation linking these terms. \n",
    "        If any terms of the hypothesis with an unknown relationship with terms in the premise, identify them as (,unknown,h_k) where h_k is in the hypothesis. \n",
    "        List the relationships found.\n",
    "\n",
    "        Step 2: Align all the relationships found with the NLI labels: Entailment, Neutral, Contradiction; classifying them into groups G1, G2, G3 and G4 according to the following:\n",
    "        G1: will contain the list of relationships that align with the entailment label\n",
    "        G2: will contain the list of relationships that align with the contradiction label \n",
    "        G3: will contain the list of relationships that align with the neutrality label\n",
    "        G4: will contain the list of terms of the hypothesis with an unknown relationship with the premise. \n",
    "\n",
    "        Step 3: Analyze each group of relationships and decide on the correct label for the premise and hypothesis presented.\n",
    "\n",
    "        Respond only using the template:\n",
    "        {\n",
    "        \"Answer\": \"\",\n",
    "        \"Explanation\": \"\",\n",
    "        \"G1\":[],\n",
    "        \"G2\":[],\n",
    "        \"G3\":[],\n",
    "        \"G4\":[]\n",
    "        }\n",
    "        Fill out the template.\n",
    "            '''\n",
    "    data = {\n",
    "        \"prompt\": prompt,\n",
    "        \"model\": model,\n",
    "        \"format\": \"json\",\n",
    "        \"stream\": False,\n",
    "        \"options\": {\"temperature\": 0,\n",
    "                    \"num_ctx\":4096},\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(\"http://localhost:11434/api/generate\", json=data, stream=False,timeout=980)      \n",
    "        json_data = json.loads(response.text)\n",
    "        return True,json.dumps(json.loads(json_data[\"response\"]), indent=2)\n",
    "    except:\n",
    "        print(\"Error\")\n",
    "        #print(response.text)\n",
    "        #print(prompt)\n",
    "    return False,str(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_n=14\n",
    "ruta=\"../output2/relationships/\"\n",
    "modelos=[\"gemma2\",\"gemma2:2b\",\"llama3.1\",\"llama3.2\",\"phi3\",\"phi3:medium\"]\n",
    "corpus=[\"Scitail\",\"RTEGLUE\",\"SNLI\",\"SICK\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conjunto_etiquetas=set()\n",
    "for m in modelos:\n",
    "    for c in corpus:\n",
    "        print(\"Model\",m,\"Corpus\",c)\n",
    "        for i in range(m_n):\n",
    "            new_data = {'Answer':[]}#,'Explanation':[]}\n",
    "            mt = pd.read_pickle(ruta+c+\"/\"+c.lower()+str(i+1)+\".pickle\")\n",
    "            with open(m+\"/\"+c+\"/processed/ritB_CoT\"+str(i+1)+\".pickle\", \"rb\") as f:\n",
    "                lista_respuestas = pickle.load(f)\n",
    "            # Validar si faltan respuestas\n",
    "            j=0\n",
    "            for a in lista_respuestas:\n",
    "                try:\n",
    "                    temp_dict=json.loads(a)\n",
    "                    resp=temp_dict[\"Answer\"]\n",
    "                    if resp==\"\" or resp==\"NA\":\n",
    "                        raise Exception(\"nothing\")\n",
    "                    else:\n",
    "                        #exp=temp_dict[\"Explanation\"]\n",
    "                        new_data[\"Answer\"].append(resp)\n",
    "                        #new_data[\"Explanation\"].append(exp)\n",
    "                except:\n",
    "                    print(j)\n",
    "                    try:\n",
    "                        ex,dat=callLLM_AoT(m,mt,j)\n",
    "                        if ex==False:\n",
    "                            time.sleep(300)\n",
    "                            \n",
    "                            ex,dat=callLLM_AoT(m,mt,j)\n",
    "                            if ex==False:\n",
    "                                if('\\\"Answer\\\": \\\"Neutral\\\"' in dat or '\\\\\"Answer\\\\\": \\\\\"Neutral\\\\\"' in dat):\n",
    "                                    new_data[\"Answer\"].append(\"Neutral\")\n",
    "                                elif('\\\"Answer\\\": \\\"Entailment\\\"' in dat or '\\\\\"Answer\\\\\": \\\\\"Entailment\\\\\"' in dat):\n",
    "                                    new_data[\"Answer\"].append(\"Entailment\")\n",
    "                                elif('\\\"Answer\\\": \\\"Contradiction\\\"' in dat or '\\\\\"Answer\\\\\": \\\\\"Contradiction\\\\\"' in dat):\n",
    "                                    new_data[\"Answer\"].append(\"Contradiction\")\n",
    "                                else:\n",
    "                                    new_data[\"Answer\"].append(\"\")\n",
    "                                #new_data[\"Explanation\"].append(dat)\n",
    "                                print(\"a la segunda\")\n",
    "                                time.sleep(300)\n",
    "                            else:\n",
    "                                temp_dict=json.loads(dat)\n",
    "                                resp=temp_dict[\"Answer\"]\n",
    "                                exp=temp_dict[\"Explanation\"]\n",
    "                                new_data[\"Answer\"].append(resp)\n",
    "                                #new_data[\"Explanation\"].append(exp)\n",
    "                                print(\"Hecho\")\n",
    "                        else:\n",
    "                            temp_dict=json.loads(dat)\n",
    "                            resp=temp_dict[\"Answer\"]\n",
    "                            exp=temp_dict[\"Explanation\"]\n",
    "                            new_data[\"Answer\"].append(resp)\n",
    "                            #new_data[\"Explanation\"].append(exp)\n",
    "                            print(\"Hecho\")\n",
    "                    except:\n",
    "                        new_data[\"Answer\"].append(\"NA\")\n",
    "                        #new_data[\"Explanation\"].append(\"\")\n",
    "                        print(\"a la tercera\")\n",
    "                        time.sleep(300)\n",
    "                j+=1\n",
    "            pd.DataFrame(new_data).to_pickle(\"../LLMs2/\"+m+\"/\"+c+\"/complete/ritB_AoT\"+str(i+1)+\".pickle\")\n",
    "            print(\"../LLMs2/\"+m+\"/\"+c+\"/complete/ritB_AoT\"+str(i+1)+\".pickle\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_n=1\n",
    "ruta=\"../output2/relationships/\"\n",
    "modelos=[\"gemma2\",\"gemma2:2b\",\"llama3.1\",\"llama3.2\",\"phi3\",\"phi3:medium\"]\n",
    "corpus=[\"DIAG\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conjunto_etiquetas=set()\n",
    "for m in modelos:\n",
    "    for c in corpus:\n",
    "        print(\"Model\",m,\"Corpus\",c)\n",
    "        for i in range(m_n):\n",
    "            new_data = {'Answer':[]}#,'Explanation':[]}\n",
    "            mt = pd.read_pickle(ruta+c+\"/\"+c.lower()+str(i+1)+\".pickle\")\n",
    "            with open(m+\"/\"+c+\"/processed/ritB_CoT\"+str(i+1)+\".pickle\", \"rb\") as f:\n",
    "                lista_respuestas = pickle.load(f)\n",
    "            # Validar si faltan respuestas\n",
    "            j=0\n",
    "            for a in lista_respuestas:\n",
    "                try:\n",
    "                    temp_dict=json.loads(a)\n",
    "                    resp=temp_dict[\"Answer\"]\n",
    "                    if resp==\"\" or resp==\"NA\":\n",
    "                        raise Exception(\"nothing\")\n",
    "                    else:\n",
    "                        #exp=temp_dict[\"Explanation\"]\n",
    "                        new_data[\"Answer\"].append(resp)\n",
    "                        #new_data[\"Explanation\"].append(exp)\n",
    "                except:\n",
    "                    print(j)\n",
    "                    try:\n",
    "                        ex,dat=callLLM_AoT(m,mt,j)\n",
    "                        if ex==False:\n",
    "                            time.sleep(300)\n",
    "                            \n",
    "                            ex,dat=callLLM_AoT(m,mt,j)\n",
    "                            if ex==False:\n",
    "                                if('\\\"Answer\\\": \\\"Neutral\\\"' in dat or '\\\\\"Answer\\\\\": \\\\\"Neutral\\\\\"' in dat):\n",
    "                                    new_data[\"Answer\"].append(\"Neutral\")\n",
    "                                elif('\\\"Answer\\\": \\\"Entailment\\\"' in dat or '\\\\\"Answer\\\\\": \\\\\"Entailment\\\\\"' in dat):\n",
    "                                    new_data[\"Answer\"].append(\"Entailment\")\n",
    "                                elif('\\\"Answer\\\": \\\"Contradiction\\\"' in dat or '\\\\\"Answer\\\\\": \\\\\"Contradiction\\\\\"' in dat):\n",
    "                                    new_data[\"Answer\"].append(\"Contradiction\")\n",
    "                                else:\n",
    "                                    new_data[\"Answer\"].append(\"\")\n",
    "                                #new_data[\"Explanation\"].append(dat)\n",
    "                                print(\"a la segunda\")\n",
    "                                time.sleep(300)\n",
    "                            else:\n",
    "                                temp_dict=json.loads(dat)\n",
    "                                resp=temp_dict[\"Answer\"]\n",
    "                                exp=temp_dict[\"Explanation\"]\n",
    "                                new_data[\"Answer\"].append(resp)\n",
    "                                #new_data[\"Explanation\"].append(exp)\n",
    "                                print(\"Hecho\")\n",
    "                        else:\n",
    "                            temp_dict=json.loads(dat)\n",
    "                            resp=temp_dict[\"Answer\"]\n",
    "                            exp=temp_dict[\"Explanation\"]\n",
    "                            new_data[\"Answer\"].append(resp)\n",
    "                            #new_data[\"Explanation\"].append(exp)\n",
    "                            print(\"Hecho\")\n",
    "                    except:\n",
    "                        new_data[\"Answer\"].append(\"NA\")\n",
    "                        #new_data[\"Explanation\"].append(\"\")\n",
    "                        print(\"a la tercera\")\n",
    "                        time.sleep(300)\n",
    "                j+=1\n",
    "            pd.DataFrame(new_data).to_pickle(\"../LLMs2/\"+m+\"/\"+c+\"/complete/ritB_AoT\"+str(i+1)+\".pickle\")\n",
    "            print(\"../LLMs2/\"+m+\"/\"+c+\"/complete/ritB_AoT\"+str(i+1)+\".pickle\")\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
