{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import requests\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verification of complete information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAoT prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callLLM_SAoT(model,dfg,ind):\n",
    "    prompt = '''\n",
    "                You are an expert in Recognizing Textual Entailment over pairs of Premise and Hypothesis.\n",
    "        Classify the relationship between the given Premise and Hypothesis as one of the following: \"Entailment\", \"Neutral\" or \"Contradiction\". \n",
    "\n",
    "        Premise: '''+dfg.at[ind,\"Texto\"]+'''\n",
    "        Hypothesis: '''+ dfg.at[ind,\"Hipotesis\"]+'''\n",
    "\n",
    "        Let's think step by step\n",
    "\n",
    "        Step 1: Identify all the relationships of Generalization, Equivalence, Opposition, Concretization or Specificity between terms from the premise to the hypothesis. This process is performed for each of the terms in the hypothesis.\n",
    "        Use the next format for relationships: (p_i,rel,h_j) where p_i is a term from the premise, h_j is a term from the hypothesis, and rel is the relation linking these terms. \n",
    "        If any terms of the hypothesis with an unknown relationship with terms in the premise, identify them as (,unknown,h_k) where h_k is in the hypothesis. \n",
    "        List the relationships found.\n",
    "\n",
    "        Step 2: Align all the relationships found with the NLI labels: Entailment, Neutral, Contradiction, classifying them into groups G1, G2, G3 and G4 according to the following:\n",
    "        G1: will contain the list of generalization or equivalence relationships that usually correspond to Entailment.\n",
    "        G2: will contain the list of relationships of opposition that often correspond to Contradiction.\n",
    "        G3: will contain the list of relationships of concretization or specificity that typically correspond to Neutral.\n",
    "        G4: will contain the list of terms of the hypothesis with an unknown relationship with the premise. \n",
    "\n",
    "        Step 3: Analyze each group of relationships, weigh the groups obtained that support your decision, and classify the correct label for the premise and hypothesis presented.\n",
    "\n",
    "        Fill in the template:\n",
    "        {\n",
    "        \"G1\":[],\n",
    "        \"G2\":[],\n",
    "        \"G3\":[],\n",
    "        \"G4\":[],\n",
    "        \"Answer\": \"\",\n",
    "        \"Explanation\": \"\"\n",
    "        }\n",
    "        Respond only using the template.\n",
    "            '''\n",
    "    \n",
    "    #print(prompt)\n",
    "    # break\n",
    "    data = {\n",
    "        \"prompt\": prompt,\n",
    "        \"model\": model,\n",
    "        \"format\": \"json\",\n",
    "        \"stream\": False,\n",
    "        \"options\": {\"temperature\": 0,\n",
    "                    \"num_ctx\":4196},\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(\"http://localhost:11434/api/generate\", json=data, stream=False,timeout=1980)      \n",
    "        json_data = json.loads(response.text)\n",
    "        return True,json.dumps(json.loads(json_data[\"response\"]), indent=2)\n",
    "    except:\n",
    "        print(\"Error\")\n",
    "        #print(response.text)\n",
    "    #print(response.text)\n",
    "    return False,str(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_n=14\n",
    "ruta=\"../output2/relationships/\"\n",
    "modelos=[\"gemma2\",\"gemma2:2b\",\"llama3.1\",\"llama3.2\",\"phi3:medium\",\"phi3\"]\n",
    "corpus=[\"Scitail\",\"RTEGLUE\",\"SNLI\",\"SICK\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conjunto_etiquetas=set()\n",
    "for m in modelos:\n",
    "    for c in corpus:\n",
    "        print(\"Model\",m,\"Corpus\",c)\n",
    "        for i in range(m_n):\n",
    "            new_data = {'Answer':[]}#,'Explanation':[]} # \n",
    "            mt = pd.read_pickle(ruta+c+\"/\"+c.lower()+str(i+1)+\".pickle\")\n",
    "            with open(m+\"/\"+c+\"/processed/ritB_SAoT\"+str(i+1)+\".pickle\", \"rb\") as f:\n",
    "                lista_respuestas = pickle.load(f)\n",
    "            # Validar si faltan respuestas\n",
    "            j=0\n",
    "            for a in lista_respuestas:\n",
    "                try:\n",
    "                    temp_dict=json.loads(a)\n",
    "                    resp=temp_dict[\"Answer\"]\n",
    "                    if resp==\"\" or resp==\"NA\":\n",
    "                        raise Exception(\"Nothing\")\n",
    "                    #exp=temp_dict[\"Explanation\"]\n",
    "                    else:\n",
    "                        new_data[\"Answer\"].append(resp)\n",
    "                    #new_data[\"Explanation\"].append(exp)\n",
    "                except:\n",
    "                    print(j)\n",
    "                    try:\n",
    "                        ex,dat=callLLM_SAoT(m,mt,j)\n",
    "                        if ex==False:\n",
    "                            if('\\\"Answer\\\": \\\"Neutral\\\"' in dat or '\\\\\"Answer\\\\\": \\\\\"Neutral\\\\\"' in dat or '\\\"Answer\\\": \\\"NEUTRAL\\\"' in dat or '\\\\\"Answer\\\\\": \\\\\"NEUTRAL\\\\\"' in dat):\n",
    "                                new_data[\"Answer\"].append(\"Neutral\")\n",
    "                            elif('\\\"Answer\\\": \\\"Entailment\\\"' in dat or '\\\\\"Answer\\\\\": \\\\\"Entailment\\\\\"' in dat or '\\\"Answer\\\": \\\"ENTAILMENT\\\"' in dat or '\\\\\"Answer\\\\\": \\\\\"ENTAILMENT\\\\\"' in dat):\n",
    "                                new_data[\"Answer\"].append(\"Entailment\")\n",
    "                            elif('\\\"Answer\\\": \\\"Contradiction\\\"' in dat or '\\\\\"Answer\\\\\": \\\\\"Contradiction\\\\\"' in dat or '\\\"Answer\\\": \\\"CONTRADICTION\\\"' in dat or '\\\\\"Answer\\\\\": \\\\\"CONTRADICTION\\\\\"' in dat):\n",
    "                                new_data[\"Answer\"].append(\"Contradiction\")\n",
    "                            else:\n",
    "                                time.sleep(250)\n",
    "                                try:\n",
    "                                    ex,dat=callLLM_SAoT(m,mt,j)\n",
    "                                    if ex==False:\n",
    "                                        if('\\\"Answer\\\": \\\"Neutral\\\"' in dat or '\\\\\"Answer\\\\\": \\\\\"Neutral\\\\\"' in dat or '\\\"Answer\\\": \\\"NEUTRAL\\\"' in dat or '\\\\\"Answer\\\\\": \\\\\"NEUTRAL\\\\\"' in dat):\n",
    "                                            new_data[\"Answer\"].append(\"Neutral\")\n",
    "                                        elif('\\\"Answer\\\": \\\"Entailment\\\"' in dat or '\\\\\"Answer\\\\\": \\\\\"Entailment\\\\\"' in dat or '\\\"Answer\\\": \\\"ENTAILMENT\\\"' in dat or '\\\\\"Answer\\\\\": \\\\\"ENTAILMENT\\\\\"' in dat):\n",
    "                                            new_data[\"Answer\"].append(\"Entailment\")\n",
    "                                        elif('\\\"Answer\\\": \\\"Contradiction\\\"' in dat or '\\\\\"Answer\\\\\": \\\\\"Contradiction\\\\\"' in dat or '\\\"Answer\\\": \\\"CONTRADICTION\\\"' in dat or '\\\\\"Answer\\\\\": \\\\\"CONTRADICTION\\\\\"' in dat):\n",
    "                                            new_data[\"Answer\"].append(\"Contradiction\")\n",
    "                                        else:\n",
    "                                            new_data[\"Answer\"].append(\"\")\n",
    "                                            print(\"F\")\n",
    "                                        #new_data[\"Explanation\"].append(dat)\n",
    "                                        print(\"a la segunda\")\n",
    "                                    else:\n",
    "                                        temp_dict=json.loads(dat)\n",
    "                                        resp=temp_dict[\"Answer\"]\n",
    "                                        #exp=temp_dict[\"Explanation\"]\n",
    "                                        new_data[\"Answer\"].append(resp)\n",
    "                                        #new_data[\"Explanation\"].append(exp)\n",
    "                                        print(\"Hecho\")\n",
    "                                except:\n",
    "                                    new_data[\"Answer\"].append(\"NA\")\n",
    "                                    #new_data[\"Explanation\"].append(\"\")\n",
    "                                    print(\"a la tercera\")\n",
    "                        else:\n",
    "                            temp_dict=json.loads(dat)\n",
    "                            resp=temp_dict[\"Answer\"]\n",
    "                            #exp=temp_dict[\"Explanation\"]\n",
    "                            new_data[\"Answer\"].append(resp)\n",
    "                            #new_data[\"Explanation\"].append(exp)\n",
    "                            print(\"Hecho\")\n",
    "                    except:\n",
    "                        new_data[\"Answer\"].append(\"NA\")\n",
    "                        #new_data[\"Explanation\"].append(\"\")\n",
    "                        print(\"a la tercera\")\n",
    "                j+=1\n",
    "            pd.DataFrame(new_data).to_pickle(\"../LLMs2/\"+m+\"/\"+c+\"/complete/ritB_SAoT\"+str(i+1)+\".pickle\")\n",
    "            print(\"../LLMs2/\"+m+\"/\"+c+\"/complete/ritB_SAoT\"+str(i+1)+\".pickle\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_n=1\n",
    "ruta=\"../output2/relationships/\"\n",
    "modelos=[\"gemma2\",\"gemma2:2b\",\"llama3.1\",\"llama3.2\",\"phi3:medium\",\"phi3\"]\n",
    "corpus=[\"DIAG\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conjunto_etiquetas=set()\n",
    "for m in modelos:\n",
    "    for c in corpus:\n",
    "        print(\"Model\",m,\"Corpus\",c)\n",
    "        for i in range(m_n):\n",
    "            new_data = {'Answer':[]}#,'Explanation':[]} # \n",
    "            mt = pd.read_pickle(ruta+c+\"/\"+c.lower()+str(i+1)+\".pickle\")\n",
    "            with open(m+\"/\"+c+\"/processed/ritB_SAoT\"+str(i+1)+\".pickle\", \"rb\") as f:\n",
    "                lista_respuestas = pickle.load(f)\n",
    "            # Validar si faltan respuestas\n",
    "            j=0\n",
    "            for a in lista_respuestas:\n",
    "                try:\n",
    "                    temp_dict=json.loads(a)\n",
    "                    resp=temp_dict[\"Answer\"]\n",
    "                    if resp==\"\" or resp==\"NA\":\n",
    "                        raise Exception(\"Nothing\")\n",
    "                    #exp=temp_dict[\"Explanation\"]\n",
    "                    else:\n",
    "                        new_data[\"Answer\"].append(resp)\n",
    "                    #new_data[\"Explanation\"].append(exp)\n",
    "                except:\n",
    "                    print(j)\n",
    "                    try:\n",
    "                        ex,dat=callLLM_SAoT(m,mt,j)\n",
    "                        if ex==False:\n",
    "                            if('\\\"Answer\\\": \\\"Neutral\\\"' in dat or '\\\\\"Answer\\\\\": \\\\\"Neutral\\\\\"' in dat or '\\\"Answer\\\": \\\"NEUTRAL\\\"' in dat or '\\\\\"Answer\\\\\": \\\\\"NEUTRAL\\\\\"' in dat):\n",
    "                                new_data[\"Answer\"].append(\"Neutral\")\n",
    "                            elif('\\\"Answer\\\": \\\"Entailment\\\"' in dat or '\\\\\"Answer\\\\\": \\\\\"Entailment\\\\\"' in dat or '\\\"Answer\\\": \\\"ENTAILMENT\\\"' in dat or '\\\\\"Answer\\\\\": \\\\\"ENTAILMENT\\\\\"' in dat):\n",
    "                                new_data[\"Answer\"].append(\"Entailment\")\n",
    "                            elif('\\\"Answer\\\": \\\"Contradiction\\\"' in dat or '\\\\\"Answer\\\\\": \\\\\"Contradiction\\\\\"' in dat or '\\\"Answer\\\": \\\"CONTRADICTION\\\"' in dat or '\\\\\"Answer\\\\\": \\\\\"CONTRADICTION\\\\\"' in dat):\n",
    "                                new_data[\"Answer\"].append(\"Contradiction\")\n",
    "                            else:\n",
    "                                time.sleep(250)\n",
    "                                try:\n",
    "                                    ex,dat=callLLM_SAoT(m,mt,j)\n",
    "                                    if ex==False:\n",
    "                                        if('\\\"Answer\\\": \\\"Neutral\\\"' in dat or '\\\\\"Answer\\\\\": \\\\\"Neutral\\\\\"' in dat or '\\\"Answer\\\": \\\"NEUTRAL\\\"' in dat or '\\\\\"Answer\\\\\": \\\\\"NEUTRAL\\\\\"' in dat):\n",
    "                                            new_data[\"Answer\"].append(\"Neutral\")\n",
    "                                        elif('\\\"Answer\\\": \\\"Entailment\\\"' in dat or '\\\\\"Answer\\\\\": \\\\\"Entailment\\\\\"' in dat or '\\\"Answer\\\": \\\"ENTAILMENT\\\"' in dat or '\\\\\"Answer\\\\\": \\\\\"ENTAILMENT\\\\\"' in dat):\n",
    "                                            new_data[\"Answer\"].append(\"Entailment\")\n",
    "                                        elif('\\\"Answer\\\": \\\"Contradiction\\\"' in dat or '\\\\\"Answer\\\\\": \\\\\"Contradiction\\\\\"' in dat or '\\\"Answer\\\": \\\"CONTRADICTION\\\"' in dat or '\\\\\"Answer\\\\\": \\\\\"CONTRADICTION\\\\\"' in dat):\n",
    "                                            new_data[\"Answer\"].append(\"Contradiction\")\n",
    "                                        else:\n",
    "                                            new_data[\"Answer\"].append(\"\")\n",
    "                                            print(\"F\")\n",
    "                                        #new_data[\"Explanation\"].append(dat)\n",
    "                                        print(\"a la segunda\")\n",
    "                                    else:\n",
    "                                        temp_dict=json.loads(dat)\n",
    "                                        resp=temp_dict[\"Answer\"]\n",
    "                                        #exp=temp_dict[\"Explanation\"]\n",
    "                                        new_data[\"Answer\"].append(resp)\n",
    "                                        #new_data[\"Explanation\"].append(exp)\n",
    "                                        print(\"Hecho\")\n",
    "                                except:\n",
    "                                    new_data[\"Answer\"].append(\"NA\")\n",
    "                                    #new_data[\"Explanation\"].append(\"\")\n",
    "                                    print(\"a la tercera\")\n",
    "                        else:\n",
    "                            temp_dict=json.loads(dat)\n",
    "                            resp=temp_dict[\"Answer\"]\n",
    "                            #exp=temp_dict[\"Explanation\"]\n",
    "                            new_data[\"Answer\"].append(resp)\n",
    "                            #new_data[\"Explanation\"].append(exp)\n",
    "                            print(\"Hecho\")\n",
    "                    except:\n",
    "                        new_data[\"Answer\"].append(\"NA\")\n",
    "                        #new_data[\"Explanation\"].append(\"\")\n",
    "                        print(\"a la tercera\")\n",
    "                j+=1\n",
    "            pd.DataFrame(new_data).to_pickle(\"../LLMs2/\"+m+\"/\"+c+\"/complete/ritB_SAoT\"+str(i+1)+\".pickle\")\n",
    "            print(\"../LLMs2/\"+m+\"/\"+c+\"/complete/ritB_SAoT\"+str(i+1)+\".pickle\")\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
