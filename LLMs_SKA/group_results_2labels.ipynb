{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "import random\n",
    "from itertools import combinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapear_valor(x):\n",
    "    mapeo = {\"ENTAILMENT\": 1, \"NEUTRAL\": 0, \"CONTRADICTION\":0}\n",
    "    return mapeo.get(x, x)  # Si no está en el mapeo, devuelve el original\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertirLabel(l):\n",
    "    new_l=[]\n",
    "    for a in l: \n",
    "        if (type(a)==type(\"a\")):\n",
    "            if a.upper() in [\"ENTAILMENT\",\"ENTAILMENT,\",\"ENTAILS\",'PROBABLE ENTAILMENT', 'PROBABLY ENTAILMENT']:\n",
    "                new_l.append(1)\n",
    "            elif a.upper() in [\"NEUTRAL\",\"NEUTRAL,\"] :\n",
    "                new_l.append(0)\n",
    "            elif a.upper() in [\"CONTRADICTION\",\"CONTRADICTION,\",\"CONTRADITION\",\"CONTRADCTION\",\"NOT_ENTAILMENT\",\"NOT-ENTAILMENT\",\"NOT ENTAILMENT\"]:\n",
    "                new_l.append(0)\n",
    "            else:\n",
    "                new_l.append(9)    \n",
    "        else:\n",
    "            new_l.append(9)\n",
    "    return new_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertir(l):\n",
    "    new_l=[]\n",
    "    for a in l:\n",
    "        if (type(a)==type(\"a\")):\n",
    "            if a.upper() in [\"ENTAILMENT\",\"ENTAILMENT,\",\"ENTAILS\",'PROBABLE ENTAILMENT', 'PROBABLY ENTAILMENT']:\n",
    "                new_l.append(\"ENTAILMENT\")\n",
    "            elif a.upper() in [\"NEUTRAL\",\"NEUTRAL,\"] :\n",
    "                new_l.append(\"CONTRADICTION\")\n",
    "            elif a.upper() in [\"CONTRADICTION\",\"CONTRADICTION,\",\"CONTRADITION\",\"CONTRADCTION\",\"NOT_ENTAILMENT\",\"NOT-ENTAILMENT\",\"NOT ENTAILMENT\"]:\n",
    "                new_l.append(\"CONTRADICTION\")\n",
    "            else:\n",
    "                new_l.append(9)    \n",
    "        else:\n",
    "            new_l.append(9)\n",
    "    return new_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# obtener votos y voto majority promedios del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"RTEGLUE\",\"Scitail\"]\n",
    "models=[\"gemma2\",\"gemma2:2b\",\"llama3.1\",\"llama3.2\",\"phi3:medium\",\"phi3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combinations for G1,G2,G3,G4 -> three and two for scenarios failure\n",
    "grupos=[\"G1\",\"G2\",\"G3\",\"G4\"]\n",
    "combinationsGs = list(combinations(grupos, 3))\n",
    "combinationsGs.extend(list(combinations(grupos, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
    "labels=set()\n",
    "for m in models:\n",
    "    for d in datasets:\n",
    "        print(\"Model\",m,\"dataset\",d)\n",
    "        corpus=d.lower()\n",
    "        ruta=m+\"/\"+d+\"/complete/\"\n",
    "        salida=m+\"/\"+d+\"/answers/\"\n",
    "        data_g=\"../data/samples/\"+d+\"/\"\n",
    "        dt_data={'cv':[],'DT':[],'root':[],'deep':[],'parameters':[]}\n",
    "        for i in range(5): # CV\n",
    "            random.seed(i)\n",
    "            samples_random = random.sample(n_samples, 10)\n",
    "            n_train = set(n_samples).difference(set(samples_random))\n",
    "            #print(samples_random,n_train)\n",
    "\n",
    "            #TRAIN\n",
    "            for j in n_train:\n",
    "                new_data = {}\n",
    "\n",
    "                lista_respuestas_G1 = pd.read_pickle(ruta+\"rit_\"+str(j)+\"_G1.pickle\")[\"Answer\"].to_list()\n",
    "                lista_respuestas_G2 = pd.read_pickle(ruta+\"rit_\"+str(j)+\"_G2.pickle\")[\"Answer\"].to_list()\n",
    "                lista_respuestas_G3 = pd.read_pickle(ruta+\"rit_\"+str(j)+\"_G3.pickle\")[\"Answer\"].to_list()\n",
    "                lista_respuestas_G4 = pd.read_pickle(ruta+\"rit_\"+str(j)+\"_G4.pickle\")[\"Answer\"].to_list()\n",
    "                y_true = pd.read_pickle(data_g+corpus+str(j)+\".pickle\")[\"gold_label\"].to_list()\n",
    "                y_true = convertir(y_true)\n",
    "\n",
    "                new_data[\"G1\"]=convertir(lista_respuestas_G1)\n",
    "                new_data[\"G2\"]=convertir(lista_respuestas_G2)\n",
    "                new_data[\"G3\"]=convertir(lista_respuestas_G3)\n",
    "                new_data[\"G4\"]=convertir(lista_respuestas_G4)\n",
    "                new_data[\"gold_label\"]=y_true\n",
    "                #print(j,len(convertir(lista_respuestas_G1)),len(convertir(lista_respuestas_G2)),len(convertir(lista_respuestas_G3)),len(convertir(lista_respuestas_G4)),len(convertir(y_true)))\n",
    "                new_data = pd.DataFrame(new_data)\n",
    "                \n",
    "                labels=labels.union(set(lista_respuestas_G1))\n",
    "                labels=labels.union(set(lista_respuestas_G2))\n",
    "                labels=labels.union(set(lista_respuestas_G3))\n",
    "                labels=labels.union(set(lista_respuestas_G4))\n",
    "                #Checar aciertos para cada grupo\n",
    "                #aciertos\n",
    "                v_a_G1=[]\n",
    "                v_a_G2=[]\n",
    "                v_a_G3=[]\n",
    "                v_a_G4=[]\n",
    "                v_a_ST=[]\n",
    "                        \n",
    "                for index,strings in new_data.iterrows():\n",
    "                    if str(strings[\"G1\"]).upper()==str(strings[\"gold_label\"]).upper():\n",
    "                        v_a_G1.append(1)\n",
    "                    else:\n",
    "                        v_a_G1.append(0)\n",
    "                    if str(strings[\"G2\"]).upper()==str(strings[\"gold_label\"]).upper():\n",
    "                        v_a_G2.append(1)\n",
    "                    else:\n",
    "                        v_a_G2.append(0)\n",
    "                    if str(strings[\"G3\"]).upper()==str(strings[\"gold_label\"]).upper():\n",
    "                        v_a_G3.append(1)\n",
    "                    else:\n",
    "                        v_a_G3.append(0)\n",
    "                    if str(strings[\"G4\"]).upper()==str(strings[\"gold_label\"]).upper():\n",
    "                        v_a_G4.append(1)\n",
    "                    else:\n",
    "                        v_a_G4.append(0)\n",
    "\n",
    "                # probar sobre la aportación de cada grupo\n",
    "                new_data[\"G1_aciertos\"]=v_a_G1\n",
    "                new_data[\"G2_aciertos\"]=v_a_G2\n",
    "                new_data[\"G3_aciertos\"]=v_a_G3\n",
    "                new_data[\"G4_aciertos\"]=v_a_G4\n",
    "                \n",
    "                new_data.to_pickle(salida+\"cv\"+str(i+1)+\"/w_answers_s\"+str(j)+\".pickle\")\n",
    "\n",
    "            \n",
    "            # GS_DT\n",
    "            \n",
    "            ln_train = list(n_train)\n",
    "\n",
    "            for k in range(len(ln_train)):\n",
    "                if k==0:\n",
    "                    dataset_train=pd.read_pickle(salida+\"cv\"+str(i+1)+\"/w_answers_s\"+str(ln_train[k])+\".pickle\")\n",
    "                else:\n",
    "                    tempdata=pd.read_pickle(salida+\"cv\"+str(i+1)+\"/w_answers_s\"+str(ln_train[k])+\".pickle\")\n",
    "                    dataset_train=pd.concat([dataset_train,tempdata],axis=0)\n",
    "            dataset_train=dataset_train.reset_index(drop=True)\n",
    "\n",
    "            data_X=dataset_train[[\"G1\",\"G2\",\"G3\",\"G4\"]].map(mapear_valor)\n",
    "            data_Y=dataset_train[\"gold_label\"].map(mapear_valor).values\n",
    "            \n",
    "            clf = DecisionTreeClassifier(random_state=i)\n",
    "            clf.fit(data_X, data_Y)\n",
    "            \n",
    "            #save parameters of DT\n",
    "\n",
    "            dt_data[\"cv\"].append(i+1)\n",
    "            dt_data[\"DT\"].append(\"SKA_DT\")\n",
    "            dt_data[\"root\"].append(\"G\"+str(clf.feature_importances_.argmax()+1))\n",
    "            dt_data[\"deep\"].append(clf.get_depth())\n",
    "            dt_data[\"parameters\"].append(clf.get_params())\n",
    "            \n",
    "            # GS_DT combinatios three and two of G1,G2,G3,G4\n",
    "            DT_comb_GS=[]\n",
    "            ln_train = list(n_train)\n",
    "\n",
    "            for comb in combinationsGs:\n",
    "                if len(comb)==3:\n",
    "                    data_X=dataset_train[[comb[0],comb[1],comb[2]]].map(mapear_valor)\n",
    "                elif len(comb)==2:\n",
    "                    data_X=dataset_train[[comb[0],comb[1]]].map(mapear_valor)\n",
    "                clf_gs = DecisionTreeClassifier(random_state=i)\n",
    "                clf_gs.fit(data_X, data_Y)\n",
    "                dt_data[\"cv\"].append(i+1)\n",
    "                #save parameters of DT\n",
    "                dt_data[\"DT\"].append(comb)\n",
    "                dt_data[\"root\"].append(\"G\"+str(clf.feature_importances_.argmax()+1))\n",
    "                dt_data[\"deep\"].append(clf.get_depth())\n",
    "                dt_data[\"parameters\"].append(clf.get_params())\n",
    "                DT_comb_GS.append(clf_gs)\n",
    "\n",
    "            # Weighted VM (weights)\n",
    "            new_data_pesos={\"sample\":[],\"alpha_G1\":[],\"alpha_G2\":[],\"alpha_G3\":[],\"alpha_G4\":[],\"sumaT\":[]}\n",
    "            for k in n_train:\n",
    "                df = pd.read_pickle(salida+\"cv\"+str(i+1)+\"/w_answers_s\"+str(k)+\".pickle\")\n",
    "                alpG1=1\n",
    "                alpG2=1\n",
    "                alpG3=1\n",
    "                alpG4=1\n",
    "                alpST=1\n",
    "                for index,strings in df.iterrows():\n",
    "                    conteosE=0\n",
    "                    if strings[\"G1_aciertos\"]==0:\n",
    "                        conteosE+=1\n",
    "                    if strings[\"G2_aciertos\"]==0:\n",
    "                        conteosE+=1\n",
    "                    if strings[\"G3_aciertos\"]==0:\n",
    "                        conteosE+=1\n",
    "                    if strings[\"G4_aciertos\"]==0:\n",
    "                        conteosE+=1\n",
    "                    #print(conteosE)\n",
    "                    if strings[\"G1_aciertos\"]==1:\n",
    "                        alpG1+=conteosE/4\n",
    "                    if strings[\"G2_aciertos\"]==1:\n",
    "                        alpG2+=conteosE/4\n",
    "                    if strings[\"G3_aciertos\"]==1:\n",
    "                        alpG3+=conteosE/4\n",
    "                    if strings[\"G4_aciertos\"]==1:\n",
    "                        alpG4+=conteosE/4\n",
    "                alpG1=np.round(alpG1,0)\n",
    "                alpG2=np.round(alpG2,0)\n",
    "                alpG3=np.round(alpG3,0)\n",
    "                alpG4=np.round(alpG4,0)\n",
    "                sumaT=alpG1+alpG2+alpG3+alpG4\n",
    "                new_data_pesos[\"sample\"].append(k)\n",
    "                new_data_pesos[\"alpha_G1\"].append(alpG1)\n",
    "                new_data_pesos[\"alpha_G2\"].append(alpG2)\n",
    "                new_data_pesos[\"alpha_G3\"].append(alpG3)\n",
    "                new_data_pesos[\"alpha_G4\"].append(alpG4)\n",
    "                new_data_pesos[\"sumaT\"].append(sumaT)\n",
    "\n",
    "            new_data_pesos=pd.DataFrame(new_data_pesos)\n",
    "            new_data_pesos.to_pickle(salida+\"cv\"+str(i+1)+\"/alphas_4gs.pickle\")\n",
    "            pesos=new_data_pesos.mean().values[1:]\n",
    "\n",
    "            # get results \n",
    "            new_dataR = {'group':[],'sample':[],'accuracy':[], 'matriz_confusion':[],\n",
    "                'Contra_precision':[], 'Contra_recall':[], 'Contra_f1':[], \n",
    "                'Entail_precision':[], 'Entail_recall':[], 'Entail_f1':[],\n",
    "                'CEntailment':[],'CContradiction':[],\n",
    "                'G1_IVM':[],'G2_IVM':[],'G3_IVM':[],'G4_IVM':[]}\n",
    "\n",
    "            for j in samples_random:\n",
    "                new_data = {}\n",
    "\n",
    "                lista_respuestas_Base = pd.read_pickle(ruta+\"rit_Base_\"+str(j)+\".pickle\")[\"Answer\"].to_list()\n",
    "                lista_respuestas_AoT = pd.read_pickle(ruta+\"ritB_AoT\"+str(j)+\".pickle\")[\"Answer\"].to_list()\n",
    "                lista_respuestas_SAoT = pd.read_pickle(ruta+\"ritB_SAoT\"+str(j)+\".pickle\")[\"Answer\"].to_list()\n",
    "                lista_respuestas_SAoT_FS = pd.read_pickle(ruta+\"ritB_SAoT_FS\"+str(j)+\".pickle\")[\"Answer\"].to_list()\n",
    "                #lista_respuestas_DR = pd.read_pickle(ruta+\"rit_\"+str(j)+\"_DR_4r.pickle\")[\"Answer\"].to_list()\n",
    "                lista_respuestas_G1 = pd.read_pickle(ruta+\"rit_\"+str(j)+\"_G1.pickle\")[\"Answer\"].to_list()\n",
    "                lista_respuestas_G2 = pd.read_pickle(ruta+\"rit_\"+str(j)+\"_G2.pickle\")[\"Answer\"].to_list()\n",
    "                lista_respuestas_G3 = pd.read_pickle(ruta+\"rit_\"+str(j)+\"_G3.pickle\")[\"Answer\"].to_list()\n",
    "                lista_respuestas_G4 = pd.read_pickle(ruta+\"rit_\"+str(j)+\"_G4.pickle\")[\"Answer\"].to_list()\n",
    "                y_true = pd.read_pickle(data_g+corpus+str(j)+\".pickle\")[\"gold_label\"].to_list()\n",
    "                y_true = convertir(y_true)\n",
    "\n",
    "                new_data[\"Base\"]=convertir(lista_respuestas_Base)\n",
    "                new_data[\"AoT\"]=convertir(lista_respuestas_AoT)\n",
    "                new_data[\"SAoT\"]=convertir(lista_respuestas_SAoT)\n",
    "                new_data[\"SAoT_FS\"]=convertir(lista_respuestas_SAoT_FS)\n",
    "                #new_data[\"DR\"]=convertir(lista_respuestas_DR)\n",
    "                new_data[\"G1\"]=convertir(lista_respuestas_G1)\n",
    "                new_data[\"G2\"]=convertir(lista_respuestas_G2)\n",
    "                new_data[\"G3\"]=convertir(lista_respuestas_G3)\n",
    "                new_data[\"G4\"]=convertir(lista_respuestas_G4)\n",
    "                new_data[\"gold_label\"]=y_true\n",
    "                \n",
    "                new_data = pd.DataFrame(new_data)\n",
    "                \n",
    "                # label predict\n",
    "                labels=labels.union(set(lista_respuestas_Base))\n",
    "                labels=labels.union(set(lista_respuestas_AoT))\n",
    "                labels=labels.union(set(lista_respuestas_SAoT))\n",
    "                labels=labels.union(set(lista_respuestas_SAoT_FS))\n",
    "                labels=labels.union(set(lista_respuestas_G1))\n",
    "                labels=labels.union(set(lista_respuestas_G2))\n",
    "                labels=labels.union(set(lista_respuestas_G3))\n",
    "                labels=labels.union(set(lista_respuestas_G4))\n",
    "\n",
    "                #SKA_DT\n",
    "\n",
    "                X_test=new_data[[\"G1\",\"G2\",\"G3\",\"G4\"]].map(mapear_valor)\n",
    "                y_gold=new_data[\"gold_label\"].map(mapear_valor).values\n",
    "\n",
    "                y_pred=[]\n",
    "                for a in clf.predict(X_test):\n",
    "                    y_pred.append(a)\n",
    "                \n",
    "                eti=[]\n",
    "                for kas in y_pred:\n",
    "                    if(kas==1):\n",
    "                        eti.append(\"ENTAILMENT\")\n",
    "                    elif(kas==0):\n",
    "                        eti.append(\"CONTRADICTION\")\n",
    "\n",
    "                new_data[\"SKA_DT\"]=eti    \n",
    "\n",
    "                # get results combinations\n",
    "                m_gs=0\n",
    "                for comb in combinationsGs:\n",
    "                    if len(comb)==3:\n",
    "                        X_test=new_data[[comb[0],comb[1],comb[2]]].map(mapear_valor)\n",
    "                    elif len(comb)==2:\n",
    "                        X_test=new_data[[comb[0],comb[1]]].map(mapear_valor)\n",
    "                    \n",
    "                    y_pred=[]\n",
    "                    for a in DT_comb_GS[m_gs].predict(X_test):\n",
    "                        y_pred.append(a)\n",
    "                    \n",
    "                    eti=[]\n",
    "                    for kas in y_pred:\n",
    "                        if(kas==1):\n",
    "                            eti.append(\"ENTAILMENT\")\n",
    "                        elif(kas==0):\n",
    "                            eti.append(\"CONTRADICTION\")\n",
    "\n",
    "                    new_data[comb]=eti[:]\n",
    "                    m_gs+=1\n",
    "                \n",
    "\n",
    "                #Checar aciertos para cada grupo\n",
    "\n",
    "                #aciertos\n",
    "                v_a_G1=[]\n",
    "                v_a_G2=[]\n",
    "                v_a_G3=[]\n",
    "                v_a_G4=[]\n",
    "                v_a_ST=[]\n",
    "                \n",
    "                #voto majority\n",
    "                v_m_G1=[]\n",
    "                v_m_G2=[]\n",
    "                v_m_G3=[]\n",
    "                v_m_G4=[]\n",
    "                v_m_ST=[]\n",
    "\n",
    "                vote_majority=\"\"\n",
    "                wvote_majority=\"\"\n",
    "                v_m=[]\n",
    "                wv_m=[]\n",
    "                \n",
    "                for index,strings in new_data.iterrows():\n",
    "                    votos=[]\n",
    "                    votos.append(str(strings[\"G1\"]).upper())\n",
    "                    votos.append(str(strings[\"G2\"]).upper())\n",
    "                    votos.append(str(strings[\"G3\"]).upper())\n",
    "                    votos.append(str(strings[\"G4\"]).upper())\n",
    "\n",
    "                    if str(strings[\"G1\"]).upper()==str(strings[\"gold_label\"]).upper():\n",
    "                        v_a_G1.append(1)\n",
    "                    else:\n",
    "                        v_a_G1.append(0)\n",
    "                    if str(strings[\"G2\"]).upper()==str(strings[\"gold_label\"]).upper():\n",
    "                        v_a_G2.append(1)\n",
    "                    else:\n",
    "                        v_a_G2.append(0)\n",
    "                    if str(strings[\"G3\"]).upper()==str(strings[\"gold_label\"]).upper():\n",
    "                        v_a_G3.append(1)\n",
    "                    else:\n",
    "                        v_a_G3.append(0)\n",
    "                    if str(strings[\"G4\"]).upper()==str(strings[\"gold_label\"]).upper():\n",
    "                        v_a_G4.append(1)\n",
    "                    else:\n",
    "                        v_a_G4.append(0)\n",
    "\n",
    "                    if votos.count(\"ENTAILMENT\")>2:\n",
    "                        v_m.append(\"ENTAILMENT\")\n",
    "                        vote_majority=\"ENTAILMENT\"\n",
    "                    elif votos.count(\"CONTRADICTION\")>2:\n",
    "                        v_m.append(\"CONTRADICTION\")\n",
    "                        vote_majority=\"CONTRADICTION\"\n",
    "                    elif votos.count(\"ENTAILMENT\")==2 and votos.count(\"CONTRADICTION\")==2:\n",
    "                        random.seed(index)\n",
    "                        random_choice = random.choice([\"ENTAILMENT\", \"CONTRADICTION\"])\n",
    "                        v_m.append(random_choice)\n",
    "                        vote_majority=random_choice\n",
    "                    else:\n",
    "                        random.seed(index)\n",
    "                        random_choice = random.choice([\"ENTAILMENT\",\"CONTRADICTION\"])\n",
    "                        v_m.append(random_choice)\n",
    "                        vote_majority=random_choice\n",
    "\n",
    "                    # que grupo aporta a VM\n",
    "                    if votos[0]==vote_majority:\n",
    "                        v_m_G1.append(1)\n",
    "                    else:\n",
    "                        v_m_G1.append(0)\n",
    "                    if votos[1]==vote_majority:\n",
    "                        v_m_G2.append(1)\n",
    "                    else:\n",
    "                        v_m_G2.append(0)\n",
    "                    if votos[2]==vote_majority:\n",
    "                        v_m_G3.append(1)\n",
    "                    else:\n",
    "                        v_m_G3.append(0)\n",
    "                    if votos[3]==vote_majority:\n",
    "                        v_m_G4.append(1)\n",
    "                    else:\n",
    "                        v_m_G4.append(0)\n",
    "\n",
    "                    \n",
    "                    pEntail=0\n",
    "                    pContra=0\n",
    "                    for k in range(4):\n",
    "                        if \"ENTAILMENT\" in votos[k]:\n",
    "                            pEntail+=pesos[k]\n",
    "                        elif \"CONTRADICTION\" in votos[k]:\n",
    "                            pContra+=pesos[k]\n",
    "                    if pEntail > pContra:\n",
    "                        wvote_majority=\"ENTAILMENT\"\n",
    "                    elif pContra>pEntail:\n",
    "                        wvote_majority=\"CONTRADICTION\"\n",
    "                    else:\n",
    "                        wvote_majority=\"NA\"\n",
    "                    wv_m.append(wvote_majority)\n",
    "                # \n",
    "\n",
    "                new_data[\"SKA_MV\"]=v_m\n",
    "                new_data[\"SKA_WMV\"]=wv_m\n",
    "                new_data[\"G1_aciertos\"]=v_a_G1\n",
    "                new_data[\"G2_aciertos\"]=v_a_G2\n",
    "                new_data[\"G3_aciertos\"]=v_a_G3\n",
    "                new_data[\"G4_aciertos\"]=v_a_G4\n",
    "                new_data[\"G1_IVM\"]=v_m_G1\n",
    "                new_data[\"G2_IVM\"]=v_m_G2\n",
    "                new_data[\"G3_IVM\"]=v_m_G3\n",
    "                new_data[\"G4_IVM\"]=v_m_G4       \n",
    "\n",
    "                new_data.to_pickle(salida+\"cv\"+str(i+1)+\"/answers_s\"+str(j)+\".pickle\")\n",
    "\n",
    "                #results       \n",
    "                temp=new_data.copy()\n",
    "                y_true=convertirLabel(temp[\"gold_label\"])\n",
    "\n",
    "                coln_new=[\"Base\",\"AoT\",\"SAoT\",\"SAoT_FS\",\"SKA_MV\",\"SKA_WMV\",\"SKA_DT\",\"G1\",\"G2\",\"G3\",\"G4\"]\n",
    "                coln_new.extend(combinationsGs)\n",
    "                columData=[\"Base\",\"AoT\",\"SAoT\",\"SAoT_FS\",\"SKA_MV\",\"SKA_WMV\",\"SKA_DT\",\"G1\",\"G2\",\"G3\",\"G4\"]\n",
    "                columData.extend(combinationsGs)\n",
    "                l=0\n",
    "                for coln in columData:\n",
    "                    y_pred=convertirLabel(temp[coln])\n",
    "                    #print(coln,l+1)\n",
    "                    y_gold=[]\n",
    "                    y_predF=[]\n",
    "                    for valor in range(len(y_pred)):\n",
    "                        if y_pred[valor]!=9:\n",
    "                            y_gold.append(y_true[valor])\n",
    "                            y_predF.append(y_pred[valor])\n",
    "                    \n",
    "                    info=classification_report(y_gold, y_predF,output_dict=True)\n",
    "                    new_dataR[\"CEntailment\"].append(info['1']['support'])\n",
    "                    new_dataR[\"CContradiction\"].append(info['0']['support'])\n",
    "\n",
    "                    new_dataR[\"group\"].append(coln_new[l])\n",
    "                    new_dataR[\"sample\"].append(j)\n",
    "                    new_dataR[\"accuracy\"].append(info['accuracy'])\n",
    "                    new_dataR[\"G1_IVM\"].append(np.mean(temp[\"G1_IVM\"].values))\n",
    "                    new_dataR[\"G2_IVM\"].append(np.mean(temp[\"G2_IVM\"].values))\n",
    "                    new_dataR[\"G3_IVM\"].append(np.mean(temp[\"G3_IVM\"].values))\n",
    "                    new_dataR[\"G4_IVM\"].append(np.mean(temp[\"G4_IVM\"].values))\n",
    "                    new_dataR[\"matriz_confusion\"].append(confusion_matrix(y_gold, y_predF))\n",
    "                    new_dataR[\"Contra_precision\"].append(info['0']['precision'])\n",
    "                    new_dataR[\"Contra_recall\"].append(info['0']['recall'])\n",
    "                    new_dataR[\"Contra_f1\"].append(info['0']['f1-score'])\n",
    "                    new_dataR[\"Entail_precision\"].append(info['1']['precision'])\n",
    "                    new_dataR[\"Entail_recall\"].append(info['1']['recall'])\n",
    "                    new_dataR[\"Entail_f1\"].append(info['1']['f1-score'])\n",
    "                    l+=1\n",
    "\n",
    "            new_dataR=pd.DataFrame(new_dataR)\n",
    "            new_dataR.to_pickle(salida+\"cv\"+str(i+1)+\"/results.pickle\")\n",
    "            pd.DataFrame(dt_data).to_pickle(salida+\"parametersDT.pickle\")\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in models:\n",
    "    for d in datasets:\n",
    "        salida=m+\"/\"+d+\"/answers/\"\n",
    "        paraDT=pd.read_pickle(salida+\"/parametersDT.pickle\")\n",
    "        print(\"Model\",m,\"dataset\",d,paraDT[paraDT[\"DT\"]==\"SKA_DT\"][\"root\"].unique(),paraDT[paraDT[\"DT\"]==\"SKA_DT\"][\"deep\"].describe()[\"mean\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dic={}\n",
    "for m in models:\n",
    "    for d in datasets:\n",
    "        corpus=d.lower()\n",
    "        ruta=m+\"/\"+d+\"/complete/\"\n",
    "        salida=m+\"/\"+d+\"/answers/\"\n",
    "        data_g=\"../data/samples/\"+d+\"/\"\n",
    "        new_data1=pd.read_pickle(salida+\"cv1/results.pickle\")\n",
    "        new_data2=pd.read_pickle(salida+\"cv2/results.pickle\")\n",
    "        new_data3=pd.read_pickle(salida+\"cv3/results.pickle\")\n",
    "        new_data4=pd.read_pickle(salida+\"cv4/results.pickle\")\n",
    "        new_data5=pd.read_pickle(salida+\"cv5/results.pickle\")\n",
    "        all=pd.concat([new_data1,new_data2,new_data3,new_data4,new_data5],axis=0)\n",
    "        results_dic[m+\"_\"+d]=all\n",
    "        for p in columData:\n",
    "            if d==\"Scitail\":\n",
    "                if (all[all[\"group\"]==p][\"CEntailment\"].describe().at[\"min\"]<190):\n",
    "                    print(m,d,p,\"CEntailment\")\n",
    "                elif (all[all[\"group\"]==p][\"CContradiction\"].describe().at[\"min\"]<190):\n",
    "                    print(m,d,p,\"CContradiction\")\n",
    "            elif d==\"RTEGLUE\":\n",
    "                if (all[all[\"group\"]==p][\"CEntailment\"].describe().at[\"min\"]<90):\n",
    "                    print(m,d,p,\"CEntailment\")\n",
    "                elif (all[all[\"group\"]==p][\"CContradiction\"].describe().at[\"min\"]<90):\n",
    "                    print(m,d,p,\"CContradiction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_md=results_dic[\"phi3_Scitail\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_md[data_md[\"group\"].isin([\"Base\",\"AoT\",\"SAoT\",\"SAoT_FS\",\"SKA_DT\",\"SKA_MV\",\"SKA_WMV\"])].boxplot(by ='group', column =['accuracy'], grid = True,figsize=(20,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_md.boxplot(by ='group', column =['accuracy'], grid = True,figsize=(20,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_md.boxplot(by ='group', column =['Contra_f1'], grid = True,figsize=(20,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_md.boxplot(by ='group', column =['Entail_f1'], grid = True,figsize=(20,10))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RNN2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
