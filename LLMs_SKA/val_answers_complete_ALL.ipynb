{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verification of complete information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "definitionsE=[\"Group 1 (G1): Triplets of Generality or Equivalence. These relations usually correspond to Entailment. triplets: (ti,rel,hj) where ti is in Premise, hj is in Hypothesis and rel is the relation between ti an hj. e.g., (dog,is_a,animal) dog is in Premise, animal is in Hypothesis and relation is general between dog - animal.\",\n",
    "        \"Group 2 (G2): Triplets of Contradictory. These often indicate Contradiction. triplets: (ti,rel,hj) where ti is in Premise, hj is in Hypothesis and rel is the relation between ti an hj. e.g., (dog,distinct_from,cat) dog is in Premise, cat is in Hypothesis and relation is distinct_from between dog - cat.\",\n",
    "        \"Group 3 (G3): Triplets of Concretization, Specificity, or Contextuality. These typically correspond to Neutral. triplets: (hj, rel, ti), where ti is in Premise, hj is in Hypothesis, and rel is the relationship between ti and hj. For example, (dog, is_an, animal): animal is in Premise, dog is in Hypothesis, and the relationship is specific between animal - dog.\",\n",
    "        \"Group 4 (G4): Relations not identified or categorized.\"]\n",
    "\n",
    "gs=[\"G1\",\"G2\",\"G3\",\"G4\"]\n",
    "\n",
    "gruposLLM=[\"ConteosG1\",\"ConteosG2\",\"ConteosG3\",\"ConteosG4\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKA prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callLLM_GS(model,f_,dfg,ind):\n",
    "    prompt = '''\n",
    "        You are an expert in Recognition of Textual Entailment over pairs of Premise and Hypothesis.\n",
    "            Based on the information provided below, classify the relationship between the given Premise and Hypothesis as one of the following: \"Entailment\", \"Neutral\" or \"Contradiction\" and give an explanation. Respond only using the template:\n",
    "            {\n",
    "                \"Answer\": \"\",\n",
    "                \"Explanation\":\"\"\n",
    "            }\n",
    "            Do not modify the template.\n",
    "\n",
    "            Background Information:\n",
    "            \n",
    "                Word Relationship Groups:\n",
    "                    '''+str(definitionsE[f_])+'''\n",
    "\n",
    "            Premise and Hypothesis to Classify:\n",
    "                Premise: '''+dfg.at[ind,\"Texto\"]+'''\n",
    "                Hypothesis: '''+ dfg.at[ind,\"Hipotesis\"]+'''\n",
    "                \n",
    "            Relations:\n",
    "                '''+str(gs[f_])+''' : '''+str(dfg.at[ind,gruposLLM[f_]])+'''                     \n",
    "\n",
    "            Use the information provided to classify the relationship and give an explanation.'''\n",
    "    \n",
    "    # print(prompt)\n",
    "    # break\n",
    "    data = {\n",
    "        \"prompt\": prompt,\n",
    "        \"model\": model,\n",
    "        \"format\": \"json\",\n",
    "        \"stream\": False,\n",
    "        \"options\": {\"temperature\": 0},\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(\"http://localhost:11434/api/generate\", json=data, stream=False,timeout=180)      \n",
    "        json_data = json.loads(response.text)\n",
    "        return True,json.dumps(json.loads(json_data[\"response\"]), indent=2)\n",
    "    except:\n",
    "        print(\"Error\")\n",
    "        #print(response.text)\n",
    "        #print(prompt)\n",
    "    return False,str(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grupos=[\"G1\",\"G2\",\"G3\",\"G4\"]\n",
    "m_n=14\n",
    "ruta=\"../output2/relationships/\"\n",
    "modelos=[\"gemma2\",\"gemma2:2b\",\"llama3.1\",\"llama3.2\",\"phi3\",\"phi3:medium\"]\n",
    "corpus=[\"Scitail\",\"RTEGLUE\",\"SNLI\",\"SICK\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conjunto_etiquetas=set()\n",
    "for m in modelos:\n",
    "    for c in corpus:\n",
    "        print(\"Model\",m,\"Corpus\",c)\n",
    "        for g in range(len(grupos)):\n",
    "            for i in range(m_n):\n",
    "                new_data = {'Answer':[],'Explanation':[]}\n",
    "                mt = pd.read_pickle(ruta+corpus.lower()+str(i+1)+\".pickle\")\n",
    "                with open(\"processed/rit_\"+str(i+1)+\"_\"+grupos[g]+\".pickle\", \"rb\") as f:\n",
    "                    lista_respuestas = pickle.load(f)\n",
    "                # Validar si faltan respuestas\n",
    "                j=0\n",
    "                for a in lista_respuestas:\n",
    "                    try:\n",
    "                        temp_dict=json.loads(a)\n",
    "                        resp=temp_dict[\"Answer\"]\n",
    "                        exp=temp_dict[\"Explanation\"]\n",
    "                        new_data[\"Answer\"].append(resp)\n",
    "                        new_data[\"Explanation\"].append(exp)\n",
    "                    except:\n",
    "                        print(j)\n",
    "                        if g<4:\n",
    "                            ex,dat=callLLM_GS(m,g,mt,j)\n",
    "                        if ex==False:\n",
    "                            if('\\\"Answer\\\": \\\"Neutral\\\"' in dat or '\\\\\"Answer\\\\\": \\\\\"Neutral\\\\\"' in dat):\n",
    "                                new_data[\"Answer\"].append(\"Neutral\")\n",
    "                            elif('\\\"Answer\\\": \\\"Entailment\\\"' in dat or '\\\\\"Answer\\\\\": \\\\\"Entailment\\\\\"' in dat):\n",
    "                                new_data[\"Answer\"].append(\"Entailment\")\n",
    "                            elif('\\\"Answer\\\": \\\"Contradiction\\\"' in dat or '\\\\\"Answer\\\\\": \\\\\"Contradiction\\\\\"' in dat):\n",
    "                                new_data[\"Answer\"].append(\"Contradiction\")\n",
    "                            else:\n",
    "                                new_data[\"Answer\"].append(\"\")\n",
    "                            new_data[\"Explanation\"].append(dat)\n",
    "                            print(\"a la segunda\")\n",
    "                        else:\n",
    "                            temp_dict=json.loads(dat)\n",
    "                            resp=temp_dict[\"Answer\"]\n",
    "                            exp=temp_dict[\"Explanation\"]\n",
    "                            new_data[\"Answer\"].append(resp)\n",
    "                            new_data[\"Explanation\"].append(exp)\n",
    "                            print(\"Hecho\")\n",
    "                    j+=1\n",
    "                pd.DataFrame(new_data).to_pickle(\"../LLMs2/\"+m+\"/\"+c+\"/complete/rit_\"+str(i+1)+\"_\"+grupos[g]+\".pickle\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_n=1\n",
    "ruta=\"../output2/relationships/\"\n",
    "modelos=[\"gemma2\",\"gemma2:2b\",\"llama3.1\",\"llama3.2\",\"phi3\",\"phi3:medium\"]\n",
    "corpus=[\"DIAG\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conjunto_etiquetas=set()\n",
    "for m in modelos:\n",
    "    for c in corpus:\n",
    "        print(\"Model\",m,\"Corpus\",c)\n",
    "        for g in range(len(grupos)):\n",
    "            for i in range(m_n):\n",
    "                new_data = {'Answer':[],'Explanation':[]}\n",
    "                mt = pd.read_pickle(ruta+corpus.lower()+str(i+1)+\".pickle\")\n",
    "                with open(\"processed/rit_\"+str(i+1)+\"_\"+grupos[g]+\".pickle\", \"rb\") as f:\n",
    "                    lista_respuestas = pickle.load(f)\n",
    "                # Validar si faltan respuestas\n",
    "                j=0\n",
    "                for a in lista_respuestas:\n",
    "                    try:\n",
    "                        temp_dict=json.loads(a)\n",
    "                        resp=temp_dict[\"Answer\"]\n",
    "                        exp=temp_dict[\"Explanation\"]\n",
    "                        new_data[\"Answer\"].append(resp)\n",
    "                        new_data[\"Explanation\"].append(exp)\n",
    "                    except:\n",
    "                        print(j)\n",
    "                        if g<4:\n",
    "                            ex,dat=callLLM_GS(m,g,mt,j)\n",
    "                        if ex==False:\n",
    "                            if('\\\"Answer\\\": \\\"Neutral\\\"' in dat or '\\\\\"Answer\\\\\": \\\\\"Neutral\\\\\"' in dat):\n",
    "                                new_data[\"Answer\"].append(\"Neutral\")\n",
    "                            elif('\\\"Answer\\\": \\\"Entailment\\\"' in dat or '\\\\\"Answer\\\\\": \\\\\"Entailment\\\\\"' in dat):\n",
    "                                new_data[\"Answer\"].append(\"Entailment\")\n",
    "                            elif('\\\"Answer\\\": \\\"Contradiction\\\"' in dat or '\\\\\"Answer\\\\\": \\\\\"Contradiction\\\\\"' in dat):\n",
    "                                new_data[\"Answer\"].append(\"Contradiction\")\n",
    "                            else:\n",
    "                                new_data[\"Answer\"].append(\"\")\n",
    "                            new_data[\"Explanation\"].append(dat)\n",
    "                            print(\"a la segunda\")\n",
    "                        else:\n",
    "                            temp_dict=json.loads(dat)\n",
    "                            resp=temp_dict[\"Answer\"]\n",
    "                            exp=temp_dict[\"Explanation\"]\n",
    "                            new_data[\"Answer\"].append(resp)\n",
    "                            new_data[\"Explanation\"].append(exp)\n",
    "                            print(\"Hecho\")\n",
    "                    j+=1\n",
    "                pd.DataFrame(new_data).to_pickle(\"../LLMs2/\"+m+\"/\"+c+\"/complete/rit_\"+str(i+1)+\"_\"+grupos[g]+\".pickle\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
